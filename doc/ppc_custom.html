<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Donny Williams" />


<title>Custom Network Comparisons</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Custom Network Comparisons</h1>
<h4 class="author">Donny Williams</h4>
<h4 class="date">5/19/2020</h4>


<div id="TOC">
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#basic-idea">Basic Idea</a><ul>
<li><a href="#r-packages">R packages</a></li>
<li><a href="#data">Data</a></li>
</ul></li>
<li><a href="#illustrative-examples">Illustrative Examples</a><ul>
<li><a href="#correlation">Correlation</a><ul>
<li><a href="#step-1-define-custom-function">Step 1: Define Custom Function</a></li>
<li><a href="#step-2-compute-the-observed-score">Step 2: Compute the Observed Score</a></li>
<li><a href="#step-3-predictive-check">Step 3: Predictive Check</a></li>
</ul></li>
<li><a href="#hamming-distance">Hamming Distance</a><ul>
<li><a href="#step-1-define-custom-function-1">Step 1: Define Custom Function</a></li>
<li><a href="#step-2-compute-the-observed-score-1">Step 2: Compute the Observed Score</a></li>
<li><a href="#step-3-predictive-check-1">Step 3: Predictive Check</a></li>
</ul></li>
<li><a href="#partial-correlation-matrix-distance">Partial Correlation Matrix Distance</a><ul>
<li><a href="#step-1-define-custom-function-2">Step 1: Define Custom Function</a></li>
<li><a href="#step-2-compute-the-observed-score-2">Step 2: Compute the Observed Score</a></li>
<li><a href="#step-3-predictive-check-2">Step 3: Predictive Check</a></li>
</ul></li>
<li><a href="#assortment">Assortment</a><ul>
<li><a href="#step-1-define-custom-function-3">Step 1: Define Custom Function</a></li>
<li><a href="#step-2-compute-the-observed-score-3">Step 2: Compute the Observed Score</a></li>
<li><a href="#step-3-predictive-check-3">Step 3: Predictive Check</a></li>
</ul></li>
<li><a href="#expected-influence">Expected Influence</a><ul>
<li><a href="#step-1-define-custom-function-4">Step 1: Define Custom Function</a></li>
<li><a href="#step-2-compute-the-observed-score-4">Step 2: Compute the Observed Score</a></li>
<li><a href="#step-3-predictive-check-4">Step 3: Predictive Check</a></li>
</ul></li>
</ul></li>
<li><a href="#two-notes-of-caution">Two Notes of Caution</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="background" class="section level1">
<h1>Background</h1>
<p>It is quite common to have partial correlation networks (GGMs) for various subgroups, say, males and females, a control and treatment group, or perhaps several educational levels. In this case, it is important to not only determine whether the groups are different, but actually compare the groups in a way that answers a specific question of interest.</p>
<p>To date, most <code>R</code> packages provide a few ways to compare groups, including <strong>BGGM</strong> (version <code>1.0.0</code>). In version <code>2.0.0</code>, however, <strong>BGGM</strong> includes a new feature for the function <code>ggm_compare_ppc</code> that enables users to <strong>compare networks in any way they want</strong>.</p>
</div>
<div id="basic-idea" class="section level1">
<h1>Basic Idea</h1>
<p>The technical details of the approach are described in <span class="citation">(Williams et al. 2020)</span>. The basic idea is to</p>
<ol style="list-style-type: decimal">
<li><p>Draw samples from the posterior distribution, assuming the groups are equal (i.e., the “null” model).</p></li>
<li><p>Generate the posterior <strong>predictive</strong> distribution for the chosen test-statistic (how the groups are being compared)</p>
<ul>
<li>This can be understood as what we would expect to observe in the future (e.g., in replication), assuming the groups were in fact equal.</li>
</ul></li>
<li><p>Compute the test-statistic for the observed groups.</p></li>
<li><p>Then compare the observed test-statistic to the predictive distribution (what is expected under the “null” model).</p>
<ul>
<li>If the observed error is larger than the model assuming group equality, this suggests that the groups are different.</li>
</ul></li>
</ol>
<p>In <strong>BGGM</strong>, the default is to compare the groups with respect to (symmetric) Kullback-Leibler divergence (i.e., “distance” between multivariate normal distributions) and the sum of squared error (for the partial correlation matrix). This was shown to be quite powerful in <span class="citation">Williams et al. (2020)</span>, while also having a low false positive rate.</p>
<p>In the following, the focus is on defining custom functions and using them with <code>ggm_compare_ppc</code>. In all examples, post-traumatic stress disorder networks are compared <span class="citation">(Fried et al. 2018)</span>.</p>
<div id="r-packages" class="section level3">
<h3>R packages</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="co"># need the developmental version</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="cf">if</span> (<span class="op">!</span><span class="kw">requireNamespace</span>(<span class="st">&quot;remotes&quot;</span>)) { </a>
<a class="sourceLine" id="cb1-3" title="3">  <span class="kw">install.packages</span>(<span class="st">&quot;remotes&quot;</span>)   </a>
<a class="sourceLine" id="cb1-4" title="4">}   </a>
<a class="sourceLine" id="cb1-5" title="5"></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="co"># install from github</span></a>
<a class="sourceLine" id="cb1-7" title="7">remotes<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;donaldRwilliams/BGGM&quot;</span>)</a></code></pre></div>
</div>
<div id="data" class="section level3">
<h3>Data</h3>
<p>Only the correlation matrices are available. Hence, multivariate normal data is generated with that <em>exact</em> correlation structure via the <code>R</code> package <strong>MASS</strong>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># need these packages</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="kw">library</span>(BGGM)</a>
<a class="sourceLine" id="cb2-3" title="3"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb2-4" title="4"><span class="kw">library</span>(assortnet)</a>
<a class="sourceLine" id="cb2-5" title="5"><span class="kw">library</span>(networktools)</a>
<a class="sourceLine" id="cb2-6" title="6"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb2-7" title="7"></a>
<a class="sourceLine" id="cb2-8" title="8"><span class="co"># group 1</span></a>
<a class="sourceLine" id="cb2-9" title="9">Yg1 &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">926</span>, </a>
<a class="sourceLine" id="cb2-10" title="10">                     <span class="dt">mu =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">16</span>), </a>
<a class="sourceLine" id="cb2-11" title="11">                     <span class="dt">Sigma =</span> ptsd_cor3, </a>
<a class="sourceLine" id="cb2-12" title="12">                     <span class="dt">empirical =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb2-13" title="13"></a>
<a class="sourceLine" id="cb2-14" title="14"><span class="co"># group 2</span></a>
<a class="sourceLine" id="cb2-15" title="15">Yg2 &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">956</span>, </a>
<a class="sourceLine" id="cb2-16" title="16">                     <span class="dt">mu =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">16</span>), </a>
<a class="sourceLine" id="cb2-17" title="17">                     <span class="dt">Sigma =</span> ptsd_cor4, </a>
<a class="sourceLine" id="cb2-18" title="18">                     <span class="dt">empirical =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
</div>
</div>
<div id="illustrative-examples" class="section level1">
<h1>Illustrative Examples</h1>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<p>This first example looks at the correlation between partial correlations of the two networks. Note that it could be two networks have what is considered a large correlation. However, the question here is, assuming the groups are equal, just how large should the correlation be? This is needed to interpret the observed test-statistic.</p>
<div id="step-1-define-custom-function" class="section level3">
<h3>Step 1: Define Custom Function</h3>
<p>The first step is to define a custom function that takes two data matrices and the output is the chosen test-statistic (in this case a correlation)</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1">f &lt;-<span class="st"> </span><span class="cf">function</span>(Yg1, Yg2){</a>
<a class="sourceLine" id="cb3-2" title="2">  <span class="co"># number of nodes</span></a>
<a class="sourceLine" id="cb3-3" title="3">  p &lt;-<span class="st"> </span><span class="kw">ncol</span>(Yg1)</a>
<a class="sourceLine" id="cb3-4" title="4">  </a>
<a class="sourceLine" id="cb3-5" title="5">  <span class="co"># index of off-diagonal</span></a>
<a class="sourceLine" id="cb3-6" title="6">  indices &lt;-<span class="st"> </span><span class="kw">upper.tri</span>( <span class="kw">diag</span>(p))</a>
<a class="sourceLine" id="cb3-7" title="7">  </a>
<a class="sourceLine" id="cb3-8" title="8">  <span class="co"># group 1:</span></a>
<a class="sourceLine" id="cb3-9" title="9">  <span class="co"># fit model</span></a>
<a class="sourceLine" id="cb3-10" title="10">  g1_fit &lt;-<span class="st"> </span><span class="kw">estimate</span>(Yg1, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb3-11" title="11">  <span class="co"># pcors</span></a>
<a class="sourceLine" id="cb3-12" title="12">  g1_pcors &lt;-<span class="st"> </span><span class="kw">pcor_mat</span>(g1_fit)[indices]</a>
<a class="sourceLine" id="cb3-13" title="13">  </a>
<a class="sourceLine" id="cb3-14" title="14">  <span class="co"># group 2</span></a>
<a class="sourceLine" id="cb3-15" title="15">  <span class="co"># fit model</span></a>
<a class="sourceLine" id="cb3-16" title="16">  g2_fit &lt;-<span class="st"> </span><span class="kw">estimate</span>(Yg2, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb3-17" title="17">  <span class="co"># pcors</span></a>
<a class="sourceLine" id="cb3-18" title="18">  g2_pcors &lt;-<span class="st"> </span><span class="kw">pcor_mat</span>(g2_fit)[indices]</a>
<a class="sourceLine" id="cb3-19" title="19">  </a>
<a class="sourceLine" id="cb3-20" title="20">  <span class="co"># test-statistic</span></a>
<a class="sourceLine" id="cb3-21" title="21">  <span class="kw">cor</span>(g1_pcors, g2_pcors)</a>
<a class="sourceLine" id="cb3-22" title="22">  }</a></code></pre></div>
</div>
<div id="step-2-compute-the-observed-score" class="section level3">
<h3>Step 2: Compute the Observed Score</h3>
<p>The next step is to compute the observed test-statistic, that is, the correlation between the partial correlations.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1">obs &lt;-<span class="st"> </span><span class="kw">f</span>(Yg1, Yg2)</a>
<a class="sourceLine" id="cb4-2" title="2"></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="co"># observed</span></a>
<a class="sourceLine" id="cb4-4" title="4">obs</a></code></pre></div>
<pre><code>## [1] 0.5399268</code></pre>
</div>
<div id="step-3-predictive-check" class="section level3">
<h3>Step 3: Predictive Check</h3>
<p>With the function, <code>f</code>, and the observed scores, <code>obs</code>, in hand, what is left is the predictive check</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1">ppc &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">ggm_compare_ppc</span>(Yg1, Yg2, </a>
<a class="sourceLine" id="cb6-2" title="2">                       <span class="dt">FUN =</span> f, </a>
<a class="sourceLine" id="cb6-3" title="3">                       <span class="dt">custom_obs =</span> obs, </a>
<a class="sourceLine" id="cb6-4" title="4">                       <span class="dt">iter =</span> <span class="dv">1000</span>, </a>
<a class="sourceLine" id="cb6-5" title="5">                       <span class="dt">loss =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>Note that <code>loss = FALSE</code> controls how the p-value is computed. It is an indicator of whether the test-statistic is a “loss” (a bad thing). In this case, a large correlation is a good thing so it is set to <code>FALSE</code>. The results can then be printed</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">ppc</a></code></pre></div>
<pre><code>## BGGM: Bayesian Gaussian Graphical Models 
## --- 
## Test: Global Predictive Check 
## Posterior Samples: 1000 
##   Group 1: 926 
##   Group 2: 956 
## Nodes:  16 
## Relations: 120 
## --- 
## Call: 
## BGGM::ggm_compare_ppc(Yg1, Yg2, iter = 1000, FUN = f, custom_obs = obs, 
##     loss = FALSE)
## --- 
## Custom: 
##  
##    contrast custom.obs p.value
##  Yg1 vs Yg2       0.54       0
## ---</code></pre>
<p>which shows the posterior predictive p-value is zero. This indicates that the observed correlation is lower than the entire predictive distribution (the distribution of correlations for future data, assuming group equality)</p>
<p>and finally plot the results</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1"><span class="kw">plot</span>(ppc)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>The density is the predictive distribution for the correlation. Recall that this is the correlation that we would expect, given the groups were actually the same, and the black point is the observed correlation. In this case, it seems quite clear that the “null model” is inadequate–the groups are apparently quite different.</p>
</div>
</div>
<div id="hamming-distance" class="section level2">
<h2>Hamming Distance</h2>
<p>The next example is <a href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a>, which, in this case, is the squared error for the adjacency matrices. It seems reasonable to think of this as a test for different network structures or patterns of zeros and ones.</p>
<div id="step-1-define-custom-function-1" class="section level3">
<h3>Step 1: Define Custom Function</h3>
<p>The first step is to define a custom function that takes two data matrices and the output is the chosen test-statistic (in this case Hamming distance)</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1">f &lt;-<span class="st"> </span><span class="cf">function</span>(Yg1, Yg2){</a>
<a class="sourceLine" id="cb10-2" title="2">  <span class="co"># nodes</span></a>
<a class="sourceLine" id="cb10-3" title="3">  p &lt;-<span class="st"> </span><span class="kw">ncol</span>(Yg1)</a>
<a class="sourceLine" id="cb10-4" title="4">  </a>
<a class="sourceLine" id="cb10-5" title="5">  <span class="co"># index of off-diagonal</span></a>
<a class="sourceLine" id="cb10-6" title="6">  indices &lt;-<span class="st"> </span><span class="kw">upper.tri</span>( <span class="kw">diag</span>(p))</a>
<a class="sourceLine" id="cb10-7" title="7"></a>
<a class="sourceLine" id="cb10-8" title="8">  <span class="co"># fit models</span></a>
<a class="sourceLine" id="cb10-9" title="9">  fit1 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg1, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb10-10" title="10">  fit2 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg2, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb10-11" title="11">  </a>
<a class="sourceLine" id="cb10-12" title="12">  <span class="co"># select graphs</span></a>
<a class="sourceLine" id="cb10-13" title="13">  sel1 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">select</span>(fit1)</a>
<a class="sourceLine" id="cb10-14" title="14">  sel2 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">select</span>(fit2)</a>
<a class="sourceLine" id="cb10-15" title="15">  </a>
<a class="sourceLine" id="cb10-16" title="16">  <span class="co"># hamming distance</span></a>
<a class="sourceLine" id="cb10-17" title="17">  <span class="kw">sum</span>((sel1<span class="op">$</span>adj[indices] <span class="op">-</span><span class="st"> </span>sel2<span class="op">$</span>adj[indices]) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb10-18" title="18">}</a></code></pre></div>
</div>
<div id="step-2-compute-the-observed-score-1" class="section level3">
<h3>Step 2: Compute the Observed Score</h3>
<p>The next step is to compute the observed test-statistic, that is, the Hamming distance between adjacency matrices</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1">obs &lt;-<span class="st"> </span><span class="kw">f</span>(Yg1, Yg2)</a>
<a class="sourceLine" id="cb11-2" title="2"></a>
<a class="sourceLine" id="cb11-3" title="3"><span class="co"># observed</span></a>
<a class="sourceLine" id="cb11-4" title="4">obs</a></code></pre></div>
<pre><code>## [1] 60</code></pre>
</div>
<div id="step-3-predictive-check-1" class="section level3">
<h3>Step 3: Predictive Check</h3>
<p>With the function, <code>f</code>, and the observed scores, <code>obs</code>, in hand, what is left is the predictive check</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1">ppc &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">ggm_compare_ppc</span>(Yg1, Yg2, </a>
<a class="sourceLine" id="cb13-2" title="2">                       <span class="dt">FUN =</span> f, </a>
<a class="sourceLine" id="cb13-3" title="3">                       <span class="dt">custom_obs =</span> obs, </a>
<a class="sourceLine" id="cb13-4" title="4">                       <span class="dt">iter =</span> <span class="dv">1000</span>)</a></code></pre></div>
<p>The results can then be printed</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1">ppc</a></code></pre></div>
<pre><code>## BGGM: Bayesian Gaussian Graphical Models 
## --- 
## Test: Global Predictive Check 
## Posterior Samples: 1000 
##   Group 1: 926 
##   Group 2: 956 
## Nodes:  16 
## Relations: 120 
## --- 
## Call: 
## BGGM::ggm_compare_ppc(Yg1, Yg2, iter = 1000, FUN = f, custom_obs = obs)
## --- 
## Custom: 
##  
##    contrast custom.obs p.value
##  Yg1 vs Yg2         60       0
## ---</code></pre>
<p>And then plot the results</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1"><span class="kw">plot</span>(ppc)</a></code></pre></div>
<pre><code>## $plot_custom</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>This result is intriguing. Whereas the correlation looked at the relation between partial correlation, here there seems to be evidence that the adjacency matrices are different (perhaps suggesting that the conditional independence structure is different).</p>
</div>
</div>
<div id="partial-correlation-matrix-distance" class="section level2">
<h2>Partial Correlation Matrix Distance</h2>
<p>There might also be interest in the so-called correlation matrix distance <span class="citation">(Herdin et al. 2005)</span>. This is also easily tested, in this case for the partial correlation matrix.</p>
<div id="step-1-define-custom-function-2" class="section level3">
<h3>Step 1: Define Custom Function</h3>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1">f &lt;-<span class="st"> </span><span class="cf">function</span>(Yg1, Yg2){</a>
<a class="sourceLine" id="cb18-2" title="2">  <span class="co"># nodes</span></a>
<a class="sourceLine" id="cb18-3" title="3">  p &lt;-<span class="st"> </span><span class="kw">ncol</span>(Yg1)</a>
<a class="sourceLine" id="cb18-4" title="4">  </a>
<a class="sourceLine" id="cb18-5" title="5">  <span class="co"># index of off-diagonal</span></a>
<a class="sourceLine" id="cb18-6" title="6">  indices &lt;-<span class="st"> </span><span class="kw">upper.tri</span>( <span class="kw">diag</span>(p))</a>
<a class="sourceLine" id="cb18-7" title="7"></a>
<a class="sourceLine" id="cb18-8" title="8">  <span class="co"># fit models</span></a>
<a class="sourceLine" id="cb18-9" title="9">  fit1 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg1, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb18-10" title="10">  fit2 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg2, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb18-11" title="11">  </a>
<a class="sourceLine" id="cb18-12" title="12">  pcor1 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">pcor_mat</span>(fit1) </a>
<a class="sourceLine" id="cb18-13" title="13">  pcor2 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">pcor_mat</span>(fit2)</a>
<a class="sourceLine" id="cb18-14" title="14">  </a>
<a class="sourceLine" id="cb18-15" title="15">  <span class="co"># CDM for partial correlations</span></a>
<a class="sourceLine" id="cb18-16" title="16">  <span class="co"># note: numerator is the trace; denominator is the Frobenius norm</span></a>
<a class="sourceLine" id="cb18-17" title="17">  <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">sum</span>(<span class="kw">diag</span>(pcor1 <span class="op">%*%</span><span class="st"> </span>pcor2)) <span class="op">/</span><span class="st"> </span>(<span class="kw">norm</span>(pcor1, <span class="dt">type =</span> <span class="st">&quot;f&quot;</span>) <span class="op">*</span><span class="st"> </span><span class="kw">norm</span>(pcor2, <span class="dt">type =</span> <span class="st">&quot;f&quot;</span>)))</a>
<a class="sourceLine" id="cb18-18" title="18">}</a></code></pre></div>
</div>
<div id="step-2-compute-the-observed-score-2" class="section level3">
<h3>Step 2: Compute the Observed Score</h3>
<p>The next step is to compute the observed test-statistic, that is, the Partial Correlation Matrix Distance</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1">obs &lt;-<span class="st"> </span><span class="kw">f</span>(Yg1, Yg2)</a>
<a class="sourceLine" id="cb19-2" title="2"></a>
<a class="sourceLine" id="cb19-3" title="3"><span class="co"># observed</span></a>
<a class="sourceLine" id="cb19-4" title="4">obs</a></code></pre></div>
<pre><code>## [1] 0.3430489</code></pre>
</div>
<div id="step-3-predictive-check-2" class="section level3">
<h3>Step 3: Predictive Check</h3>
<p>With the function, <code>f</code>, and the observed scores, <code>obs</code>, in hand, what is left is the predictive check</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">ppc &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">ggm_compare_ppc</span>(Yg1, Yg2, </a>
<a class="sourceLine" id="cb21-2" title="2">                       <span class="dt">FUN =</span> f, </a>
<a class="sourceLine" id="cb21-3" title="3">                       <span class="dt">custom_obs =</span> obs, </a>
<a class="sourceLine" id="cb21-4" title="4">                       <span class="dt">iter =</span> <span class="dv">1000</span>)</a></code></pre></div>
<p>The results can then be printed</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" title="1">ppc</a></code></pre></div>
<pre><code>## BGGM: Bayesian Gaussian Graphical Models 
## --- 
## Test: Global Predictive Check 
## Posterior Samples: 1000 
##   Group 1: 926 
##   Group 2: 956 
## Nodes:  16 
## Relations: 120 
## --- 
## Call: 
## BGGM::ggm_compare_ppc(Yg1, Yg2, iter = 1000, FUN = f, custom_obs = obs)
## --- 
## Custom: 
##  
##    contrast custom.obs p.value
##  Yg1 vs Yg2      0.343       0
## ---</code></pre>
<p>which again provides a p-value of zero.</p>
<p>Note that the object <code>ppc</code> includes the predictive samples that allows for user defined plots (in the event something custom is desired).</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" title="1"><span class="kw">hist</span>(ppc<span class="op">$</span>predictive_custom, </a>
<a class="sourceLine" id="cb24-2" title="2">     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, obs), </a>
<a class="sourceLine" id="cb24-3" title="3">     <span class="dt">main =</span> <span class="st">&quot;Partial Correlation Matrix Distance&quot;</span>)</a>
<a class="sourceLine" id="cb24-4" title="4"><span class="kw">abline</span>(<span class="dt">v =</span> obs)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Note that the line is the observed which again makes it clear that the distance is quite surprising, assuming the null model were true.</p>
</div>
</div>
<div id="assortment" class="section level2">
<h2>Assortment</h2>
<p>This next example is assortment <span class="citation">(Newman 2003)</span>, which is a measure related to clustering in a network. Here the test is for a difference in assortment. This is computed by taking the difference (absolute value) for each draw from the predictive distribution.</p>
<div id="step-1-define-custom-function-3" class="section level3">
<h3>Step 1: Define Custom Function</h3>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1"><span class="co"># clusters based on DSM-5</span></a>
<a class="sourceLine" id="cb25-2" title="2">comms &lt;-<span class="st"> </span><span class="kw">c</span>(</a>
<a class="sourceLine" id="cb25-3" title="3">  <span class="kw">rep</span>(<span class="st">&quot;A&quot;</span>, <span class="dv">4</span>),</a>
<a class="sourceLine" id="cb25-4" title="4">  <span class="kw">rep</span>(<span class="st">&quot;B&quot;</span>, <span class="dv">7</span>),</a>
<a class="sourceLine" id="cb25-5" title="5">  <span class="kw">rep</span>(<span class="st">&quot;C&quot;</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb25-6" title="6">)</a>
<a class="sourceLine" id="cb25-7" title="7"></a>
<a class="sourceLine" id="cb25-8" title="8">f &lt;-<span class="st"> </span><span class="cf">function</span>(Yg1, Yg2){</a>
<a class="sourceLine" id="cb25-9" title="9"></a>
<a class="sourceLine" id="cb25-10" title="10">  fit1 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg1, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb25-11" title="11">  fit2 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg2, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb25-12" title="12"></a>
<a class="sourceLine" id="cb25-13" title="13">  pcor1 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">pcor_mat</span>(fit1)</a>
<a class="sourceLine" id="cb25-14" title="14">  pcor2 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">pcor_mat</span>(fit2)</a>
<a class="sourceLine" id="cb25-15" title="15"></a>
<a class="sourceLine" id="cb25-16" title="16">  assort1 &lt;-<span class="st"> </span>assortnet<span class="op">::</span><span class="kw">assortment.discrete</span>(pcor1, <span class="dt">types =</span> comms,</a>
<a class="sourceLine" id="cb25-17" title="17">                                         <span class="dt">weighted =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb25-18" title="18">                                         <span class="dt">SE =</span> <span class="ot">FALSE</span>, <span class="dt">M =</span> <span class="dv">1</span>)<span class="op">$</span>r</a>
<a class="sourceLine" id="cb25-19" title="19"></a>
<a class="sourceLine" id="cb25-20" title="20">  assort2 &lt;-<span class="st"> </span>assortnet<span class="op">::</span><span class="kw">assortment.discrete</span>(pcor2, <span class="dt">types =</span> comms,</a>
<a class="sourceLine" id="cb25-21" title="21">                                          <span class="dt">weighted =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb25-22" title="22">                                          <span class="dt">SE =</span> <span class="ot">FALSE</span>, <span class="dt">M =</span> <span class="dv">1</span>)<span class="op">$</span>r</a>
<a class="sourceLine" id="cb25-23" title="23">  (assort1 <span class="op">-</span><span class="st"> </span>assort2)</a>
<a class="sourceLine" id="cb25-24" title="24">}</a></code></pre></div>
</div>
<div id="step-2-compute-the-observed-score-3" class="section level3">
<h3>Step 2: Compute the Observed Score</h3>
<p>The next step is to compute the observed test-statistic, that is, assortment for the two groups</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" title="1">obs &lt;-<span class="st"> </span><span class="kw">f</span>(Yg1, Yg2)</a>
<a class="sourceLine" id="cb26-2" title="2"></a>
<a class="sourceLine" id="cb26-3" title="3"><span class="co"># observed</span></a>
<a class="sourceLine" id="cb26-4" title="4">obs</a></code></pre></div>
<pre><code>## [1] 0.1915766</code></pre>
</div>
<div id="step-3-predictive-check-3" class="section level3">
<h3>Step 3: Predictive Check</h3>
<p>With the function, <code>f</code>, and the observed score, <code>obs</code>, in hand, the next step is the predictive check</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" title="1">ppc &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">ggm_compare_ppc</span>(Yg1, Yg2, </a>
<a class="sourceLine" id="cb28-2" title="2">                       <span class="dt">FUN =</span> f, </a>
<a class="sourceLine" id="cb28-3" title="3">                       <span class="dt">custom_obs =</span> obs, </a>
<a class="sourceLine" id="cb28-4" title="4">                       <span class="dt">iter =</span> <span class="dv">1000</span>)</a></code></pre></div>
<p>The results can then be printed</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1">ppc</a></code></pre></div>
<pre><code>## BGGM: Bayesian Gaussian Graphical Models 
## --- 
## Test: Global Predictive Check 
## Posterior Samples: 1000 
##   Group 1: 926 
##   Group 2: 956 
## Nodes:  16 
## Relations: 120 
## --- 
## Call: 
## BGGM::ggm_compare_ppc(Yg1, Yg2, iter = 1000, FUN = f, custom_obs = obs)
## --- 
## Custom: 
##  
##    contrast custom.obs p.value
##  Yg1 vs Yg2      0.192       0
## ---</code></pre>
<p>and plotted</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="kw">plot</span>(ppc)</a></code></pre></div>
<pre><code>## $plot_custom</code></pre>
<pre><code>## Picking joint bandwidth of 0.0071</code></pre>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAz1BMVEUAAAAAADoAAGYAOmYAOpAAZrYzMzM6AAA6ADo6AGY6ZmY6kNtNTU1NTW5NTY5Nbo5NbqtNjqtNjshmAABmADpmOgBmtv9uTU1uTW5uTY5ubqtuq+SOTU2OTW6OTY6Obm6OyP+QOgCQkDqQkGaQtpCQ29uQ2/+q5aqrbk2rbm6ryKur5P+y7LK2ZgC22/+2///Ijk3I///bkDrb/9vb///kq27k/8jk/+Tk///r6+v/AAD/tmb/yI7/25D/27b/5Kv//7b//8j//9v//+T////4MhFsAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAJd0lEQVR4nO3dC3vaNhQGYNGF0Y50l7DRrWm3sHZJ2pQ1dZOtCWUhxP//N00XX2Qs6dhBxjL+ztOGwJGw/VaWhIGKxQhnsLZ3IPQAEBEAIgJARACICAARASAiAERE40BzxmNqSS6ffWx6+9tGw0DLEZMxNKejJz0HWk0kDb8xt6HeA0VsLG+Xo4Or9ezgKo7Xs6H4IU87eTOWfkxILUfjhXiA/xBFw4hGgdYzrYXkQBKGCyVAC3lvcMqBvuNn5ODtyH5O7j4aBVpNtOPMgXhLSXLiFONMU9HWDq54hzWNZRsSLa7JHasR7QClDUQALUfyznxwKn9bTXgxVTaIaANIDf3ingKSHfhCAKUtK573Ayjvg6LBqQakRn+e6ztQNoqtJlxiLrTyRjXnHc7mKdY7oHweNFYivEce8n5YsPFGJf/qnXTvgAozaTmcf/NLNsxzg2hjmO8fUIKh5tGc4+BzNlFMmhaXEIrJRLF/QJ0PABEBICIARASAiAAQEQAiAkBEAIgIABHRKNBNOUyP0ambmLFHVXtcTqQ6BsTYmU0IQCLY2ZmtDQGIB/twdmZrQgC6SYHMQgASJ5gAsjQhAAGITKVARiEAiTFeApmbEIDEGA8gVwpARCoDMgoBiPsAyJUCEJECEJECkDslfFIgkxCAAOROAYhIAcidkj4AsqcARKSKQAahngMpHwBZUwAiUgAiUgBypxIfANlSACJSJaCyUK+BUh8AWVIAIlIAcqcyHwCZUwAiUgAiUiagklCPgXIfABlTACJSACJSAHKnNB8AmVIAIlIAIlIWoE0hAAHInNJ9AGRIAYhIAYhIAYhIAcidKvgAqJyyA20IAQhAxhSAiBSAiBSA3KmiD4BKKQARKQARKRdQUQhAADKlAORObfgAaDMFICIFICIFICLlBioIAQhAhhSAiBSA3KlNHwBtpABE7DGAiD2mgHQhAAGonAIQsceBAq0mahkib+vq1d8tFSUfABVTYQJFLA1vy+fV3y0VNJAmtPsW5C/q75aKUIG8R/3dUhEsEG9Cqwnzt/Zp/d1SESzQfCjWjIvQB91Y+yCxBGEXRrHWgFaTcftAZZ9AgNaz8WJwKk608IFyoV32QXKFWI+r5+0dkO8AUN+AkkU/u9BJtwLEO+n1bOrxBce+AQmaOR/mvfXSTQJlQjsGitqfKBp8AgESMyCuE7XcggIG4p1QPBerLgMo5GE+XCA+hAHIBRTIFcVwgWJ/3fMOgFKhnbYgFsJMOlwg7/EoIJNPIEBhvC8GoK4ChfLGYbBAoQzzAQN5j2aBEqHeXTALGEi8KeY19g0oiD7I6BMIUBAvVkMG8jgD2k+gIF6L1QBSQn0b5gHUaSD5cmMMIBtQJHof8QmY9oDMPoEAhfBqHkBdBurcKSaFetZJBw7kOQDULyDZR69nHt8bq79bFp8ggJYj1fnM2/ykfchA2ad/2/wYcMBA+dWyNudBNYGEEIACARIfnlLR4ifMbD4hAKlpdEEKQAWgeC4/e7eatPhVhLCB1Nti/j6huH9A3gNArQNxoT4BWX0ABCAAAah5ILsPgADUFNAZAxCAknD4AAhAANoaiNkRALQFUHkBegD1E4gBiAByIQAIQM0B3TqE9giIOREABCAAAahRIOZGABCAGgRyCAGoL0CMQAAQgAAEoAaBGIXgBrILAQhAAAIQvVuMRADQdkBWIQABCED5e/IAag7IJgQgAAEo/1gQgBoEsggBqAdArAoCDWQWAhCAKgMZhfYAiHkDumVlon0AqoRQCcggBKACUFmo+0DMK1BJaA+AqiFUBdrsqQFUAmKurXUPqPD1DB9AtwAigIpCXQdiACKAqiLUACoIdRyIAYgAqoxQB0gX6jbQ5jcMAVTcLdYUkCbUZaCSj0egbRepDQCIlX38Ad12HsjE4xMoE+omkJnHL9B2K0e1C2Th8QqUCnUQyMrjFygRahLo4fyI/7w8yh+5++0TXezuxeHhiR3I4eMXSBHVB2JpNRIovvv1omDy9fB7A9BGsfvXF/IRMxBzfjHVMxAXqv+/Msile6qeYrxZXB7zY351+MMfF/Hl8/eS4e7ll/jh3cXXw9SrUOyrbE9pE9rYMHN/a843kDJihjc7rEDJblYEun/9nmOIo//6XLQJ1U44Dkf65/dP8fWRsZhsRXH8LY/sqRj70Fi4gPKmVC1SIP0hR/Fr0ZvccwqBkvVB18f8j0IwFns4P04zVRs2mWqgmocWpESSUyoHunv5r2hELw6fX5iK3b/KfLoHVK8PUkdeakEP7+QpxXvtH7+Ui929OMmfYCdH6hWoziiWimz0QeKUOpY4BaCkWMGni0BZqjoQH55+0luQGsYvs1GsUOz6UMSJ7Rl53+3YniPaq1apfzdOER9XbP+AHs4Ps+54+2J7COQ5ALRvASAiAEQEgIgAEBG7A+IzyWTqXXlipVfSqzezLb1aft1vZ0AP5yfpBRLbtTdXJb16M9vSq2nX/XYGJF7NJv+Y6bW3OpW06g1tS6+mXffbGZC4HpJdRap6qHmlQvVGtrW5jeS3nQGJ1/61dzqvVKjeyLY2qqXX/XYCxF/6H3WsBWXX/drog6rv9PZ9UB0grVp+XWuHo9hxPgxV3em8UqF6I9vSq2nX/XY9D1K7W3MeJIo/Yh5Uc1taNe26H2bSRACICAARASAiAEQEgIgIAWg9k+/4GhcwXTz5uHyaJ/77O9bvFiJKnsNWwFrRGWEAybWBI9Ma08WFpx3HuJ6JBXQjNt1foHw5bi0qA83VAsPRwdU+Ay2f/cmefBSnnHBZTdjgjTrFxENDuZTwePn0L1k+ygvGBd3l0zf8ZJuqU1ekVWUJtBC/1IqAgObcYjQUd4eyJawmY37cEkg8JAjEMfK/Yj1zXiktKCprzWM54g9JPpXWKi9HhkbqjjCAZCfN/7HlASxU65nK20gCpYefACU3aUGZeZadivJJtHRe+e2o/kLoYQCl+y2PJVIf8xrLtsEPPD3WOAMSFXg2LZjV1J5EtLMknVUeyROvZoQIlKznbgeKFweflVH2HGkftPr5NANK0jnQdF5/qfgAgRbJhEge2MJ0inGGt/yUWugzp4QjSuZNQnWQV0puRbdWMwIEkjMafnSryVDvpPWOOp6zYV4weZLCPEhWUum0sng8Ms5GXREgkOy0xYGUhnkJo1qZ7E3Sgirm+kw6rTQ4LQzzirFOhAAUdACICAARASAiAEQEgIgAEBEAIgJARACIiP8Bhg7RZQfS23wAAAAASUVORK5CYII=" /><!-- --></p>
<p>which shows that the clustering in the data appears to be different (given the observed value exceeds the entire predictive distribution).</p>
</div>
</div>
<div id="expected-influence" class="section level2">
<h2>Expected Influence</h2>
<p>This last example looks at the expected influence for the network <span class="citation">(Robinaugh, Millner, and McNally 2016)</span>. In this case, the sum of squared error is the test statistic. This is computed from the squared error for each draw from the predictive distribution.</p>
<div id="step-1-define-custom-function-4" class="section level3">
<h3>Step 1: Define Custom Function</h3>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1">f &lt;-<span class="st"> </span><span class="cf">function</span>(Yg1, Yg2){</a>
<a class="sourceLine" id="cb34-2" title="2"></a>
<a class="sourceLine" id="cb34-3" title="3">  fit1 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg1, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb34-4" title="4">  fit2 &lt;-<span class="st">  </span>BGGM<span class="op">::</span><span class="kw">estimate</span>(Yg2, <span class="dt">analytic =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb34-5" title="5"></a>
<a class="sourceLine" id="cb34-6" title="6">  pcor1 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">pcor_mat</span>(fit1)</a>
<a class="sourceLine" id="cb34-7" title="7">  pcor2 &lt;-<span class="st"> </span>BGGM<span class="op">::</span><span class="kw">pcor_mat</span>(fit2)</a>
<a class="sourceLine" id="cb34-8" title="8"></a>
<a class="sourceLine" id="cb34-9" title="9">  ei1 &lt;-<span class="st"> </span>networktools<span class="op">::</span><span class="kw">expectedInf</span>(pcor1)<span class="op">$</span>step1</a>
<a class="sourceLine" id="cb34-10" title="10"> </a>
<a class="sourceLine" id="cb34-11" title="11">  ei2 &lt;-<span class="st"> </span>networktools<span class="op">::</span><span class="kw">expectedInf</span>(pcor2)<span class="op">$</span>step1</a>
<a class="sourceLine" id="cb34-12" title="12">   <span class="kw">sum</span>((ei1 <span class="op">-</span><span class="st"> </span>ei2)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb34-13" title="13">}</a></code></pre></div>
</div>
<div id="step-2-compute-the-observed-score-4" class="section level3">
<h3>Step 2: Compute the Observed Score</h3>
<p>The next step is to compute the observed test-statistic, that is, the sum of squared error for expected influence</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1">obs &lt;-<span class="st"> </span><span class="kw">f</span>(Yg1, Yg2)</a>
<a class="sourceLine" id="cb35-2" title="2"></a>
<a class="sourceLine" id="cb35-3" title="3"><span class="co"># observed</span></a>
<a class="sourceLine" id="cb35-4" title="4">obs</a></code></pre></div>
<pre><code>## [1] 0.518462</code></pre>
</div>
<div id="step-3-predictive-check-4" class="section level3">
<h3>Step 3: Predictive Check</h3>
<p>With the function, <code>f</code>, and the observed scores, <code>obs</code>, in hand, what is left is the predictive check</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1">ppc &lt;-<span class="st"> </span>BGGM<span class="op">:::</span><span class="kw">ggm_compare_ppc</span>(Yg1, Yg2, </a>
<a class="sourceLine" id="cb37-2" title="2">                       <span class="dt">FUN =</span> f, </a>
<a class="sourceLine" id="cb37-3" title="3">                       <span class="dt">custom_obs =</span> obs, </a>
<a class="sourceLine" id="cb37-4" title="4">                       <span class="dt">iter =</span> <span class="dv">1000</span>)</a></code></pre></div>
<p>The results can then be printed</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" title="1">ppc</a></code></pre></div>
<pre><code>## BGGM: Bayesian Gaussian Graphical Models 
## --- 
## Test: Global Predictive Check 
## Posterior Samples: 1000 
##   Group 1: 926 
##   Group 2: 956 
## Nodes:  16 
## Relations: 120 
## --- 
## Call: 
## BGGM:::ggm_compare_ppc(Yg1, Yg2, iter = 1000, FUN = f, custom_obs = obs)
## --- 
## Custom: 
##  
##    contrast custom.obs p.value
##  Yg1 vs Yg2      0.518       0
## ---</code></pre>
<p>and plotted</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" title="1"><span class="kw">hist</span>(ppc<span class="op">$</span>predictive_custom, </a>
<a class="sourceLine" id="cb40-2" title="2">    <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, obs),</a>
<a class="sourceLine" id="cb40-3" title="3">     <span class="dt">main =</span> <span class="st">&quot;Expected Influence</span><span class="ch">\n</span><span class="st"> Sum of Squared Error&quot;</span>)</a>
<a class="sourceLine" id="cb40-4" title="4"><span class="kw">abline</span>(<span class="dt">v =</span> obs)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --> which again shows the sum of squared error for expected influence far exceeds what would be expected, assuming the null model were true.</p>
</div>
</div>
</div>
<div id="two-notes-of-caution" class="section level1">
<h1>Two Notes of Caution</h1>
<ol style="list-style-type: decimal">
<li><p>Note that only the default in <strong>BGGM</strong> have been shown to have nominal error rates. However, there is a proof that suggests the error rate cannot be larger than <span class="math inline">\(2\alpha\)</span> <span class="citation">(Meng and others 1994)</span>, and, further, a predictive check is typically below <span class="math inline">\(\alpha\)</span> <span class="citation">(i.e., a tendency to be conservative, Gelman and others 2013)</span>.</p></li>
<li><p>Failing to reject the null model does not indicate the groups are the same! To test for equality see <code>ggm_compare_explore</code> and <code>ggm_compare_confirm</code>.</p></li>
</ol>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>These example certainly open the door for tailoring network comparison to answer specific research questions.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-fried2018replicability">
<p>Fried, Eiko I, Marloes B Eidhof, Sabina Palic, Giulio Costantini, Hilde M Huisman-van Dijk, Claudi LH Bockting, Iris Engelhard, Cherie Armour, Anni BS Nielsen, and Karen-Inge Karstoft. 2018. “Replicability and Generalizability of Posttraumatic Stress Disorder (Ptsd) Networks: A Cross-Cultural Multisite Study of Ptsd Symptoms in Four Trauma Patient Samples.” <em>Clinical Psychological Science</em> 6 (3): 335–51.</p>
</div>
<div id="ref-gelman2013two">
<p>Gelman, Andrew, and others. 2013. “Two Simple Examples for Understanding Posterior P-Values Whose Distributions Are Far from Uniform.” <em>Electronic Journal of Statistics</em> 7: 2595–2602.</p>
</div>
<div id="ref-herdin2005correlation">
<p>Herdin, Markus, Nicolai Czink, Hüseyin Ozcelik, and Ernst Bonek. 2005. “Correlation Matrix Distance, a Meaningful Measure for Evaluation of Non-Stationary Mimo Channels.” In <em>2005 Ieee 61st Vehicular Technology Conference</em>, 1:136–40. IEEE.</p>
</div>
<div id="ref-meng1994posterior">
<p>Meng, Xiao-Li, and others. 1994. “Posterior Predictive <span class="math inline">\(p\)</span>-Values.” <em>The Annals of Statistics</em> 22 (3): 1142–60.</p>
</div>
<div id="ref-newman2003mixing">
<p>Newman, Mark EJ. 2003. “Mixing Patterns in Networks.” <em>Physical Review E</em> 67 (2): 026126.</p>
</div>
<div id="ref-robinaugh2016identifying">
<p>Robinaugh, Donald J, Alexander J Millner, and Richard J McNally. 2016. “Identifying Highly Influential Nodes in the Complicated Grief Network.” <em>Journal of Abnormal Psychology</em> 125 (6): 747.</p>
</div>
<div id="ref-williams2020comparing">
<p>Williams, Donald R., Philippe Rast, Luis R Pericchi, and Joris Mulder. 2020. “Comparing Gaussian Graphical Models with the Posterior Predictive Distribution and Bayesian Model Selection.” <em>Psychological Methods</em>.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
