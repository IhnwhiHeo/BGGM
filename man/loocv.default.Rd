% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/loocv.default.R
\name{loocv.default}
\alias{loocv.default}
\title{Nodewise Leave-One-Out Cross-Validation}
\usage{
\method{loocv}{default}(x, ci_width = 0.95, samples = 100, n_cl = 2)
}
\arguments{
\item{x}{fitted model}

\item{ci_width}{credible interval width for selected edges}

\item{samples}{number of samples (\code{analytic = FALSE})}

\item{n_cl}{number of clusters (see notes)}
}
\value{
list of class \code{loocv}:

\itemize{

\item \code{returned_object} data.frame summary of predictability
\item \code{call} \code{match.call()}
\item \code{samples} number of samples used for computing Bayesian loo
}
}
\description{
Assesses the predictability of each node in the "network" of GGM. Currently there are two options avaliable. The first is Bayesian
leave-one-out cross-validation and has a measure of uncertainty, whereas the latter is based only on the point estimates and is known as PRESS
(predicted residual sums of squares).
}
\note{
This function can be used to compute leave-one-out prediction error analytically for each node in the selected graph. This uses the point estimates
for the coefficients, and thus does not provide a measure of uncertainty. Becuase this solution is fast it allows for computing, say, prediction error
while adjusting the \emph{p} to \emph{n} ratio. This can provide insight into overfitting. See here for the derivations:
 \href{https://robjhyndman.com/hyndsight/loocv-linear-models/}{analytic CV}.

 Ideally, Bayesian (approximate) leave-one-out (loo) cross-validation should be computed. This requires posterior samples, which provides a measure
 of uncertainty--i.e., a standard error. This is computationally more involved
 than the analytic expression, but still much (much) faster than prediciting individual data points. \code{n_cl} allows for parallel computation.
 \code{samples} number of posterior samples used for computing loo (cannot exceed the number of samples in the fitted model).

 This approach should \strong{not} be used to explicitly compare nodes, as each is fit to a different outcome. However, because the variables are on
 the same scale (standardized in advance), it is seems that one could infer which node in the graph is the easiest to predict.

 methods(class = "loocv")
}
\examples{

X <- BGGM::bfi[,1:5]

###########################
##### Bayesian loocv ######
###########################
fit <- estimate(X,
                analytic = FALSE,
               samples = 500)

nodewise_loo <- loocv(fit,
                      ci_width = 0.99,
                      samples = 250,
                      n_cl = detectCores() - 1)
# summary
summary(nodewise_loo)

# plot
plot(nodewise_loo,
    size = 4,
     color = "brown4") +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()) +
  ggtitle("Bayesian Leave-One-Out Cross-Validation") +
  ylab("Leave-One-Out Prediction Error \\n (lower is better)") +
  xlab("Node")


###########################
##### analytic loocv ######
###########################
fit <- estimate(X,
                analytic = TRUE)

nodewise_loo <- loocv(fit,
                      ci_width = 0.99)
# summary
summary(nodewise_loo)

# plot
plot(nodewise_loo,
     size = 6,
     color = "pink") +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  ggtitle("Leave-One-Out Cross-Validation") +
  ylab("Leave-One-Out Prediction Error \\n (lower is better)") +
  xlab("Node") +
  scale_y_continuous(limits = c(0, 2500),
                     expand = c(0, 0))
}
\references{
Allen, D. M. (1971). Mean square error of prediction as a criterion for selecting variables. Technometrics, 13(3), 469-475.

Gelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for Bayesian models.
Statistics and computing, 24(6), 997-1016.

Vehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation
and WAIC. Statistics and Computing, 27(5), 1413-1432.
}
